version: '3.8'

services:
  xinference:
    image: xprobe/xinference:latest
    ports:
      - "9997:9997"
    volumes:
      #      # Replace <xinference_home> with your xinference home path on the host machine
      - ~/models/local:/root/.xinference
      #      # Replace <huggingface_cache_dir> with your huggingface cache path, default is
      #      # <home_path>/.cache/huggingface
      - ~/models/huggingface:/root/.cache/huggingface
      #      # If models are downloaded from modelscope, replace <huggingface_cache_dir> with
      #      # your modelscope cache path, default is <home_path>/.cache/modelscope
      #- ~/models/modelscope:/root/.cache/modelscope
    environment:
      #      # add envs here. Here's an example, if you want to download model from modelscope
      #- XINFERENCE_MODEL_SRC=modelscope
    command: xinference-local --host 0.0.0.0 --port 9997
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [ gpu ]
              driver: nvidia
              count: all

networks:
  default:
    driver: bridge
